{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e9cf01-ba72-4d77-a681-d563add72d69",
   "metadata": {},
   "source": [
    "# Tutorial 3: LQR for a double pendulum\n",
    "In this tutorial we will use our knowledge about the double pendulum to create optimal controllers that hold keep the robot in one of its unstable points of equilibrium. We will also introduce the acrobot and pendubot, two classical examples of underactuated robots. \n",
    "\n",
    "**Pre-requisites**\n",
    "\n",
    "Knowledge of the dynamics of the double pendulum, as well as basic notions of LQRs and the concept of the region of attraction.\n",
    "\n",
    "**Goals**\n",
    "\n",
    "Deriving and implementing a linear quadratic regulators for an underactuated double pendulum.\n",
    "\n",
    "This notebook is organized as follows:\n",
    "\n",
    "    1. Derivation\n",
    "    2. Implementation\n",
    "    3. Region of attraction\n",
    "    4. Maximizing the RoA with CMA-ES\n",
    "\n",
    "Run the next cell to make sure you have all the necessary dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07303cfc-67ec-4aaf-a372-7b1b925cbd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfbdfc-a254-4998-82b6-a76b6c30be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as smp\n",
    "from datetime import datetime\n",
    "from double_pendulum.model.symbolic_plant import SymbolicDoublePendulum, diff_to_matrix, sub_symbols\n",
    "from double_pendulum.model.model_parameters import model_parameters\n",
    "from double_pendulum.simulation.simulation import Simulator\n",
    "from double_pendulum.controller.lqr.lqr_controller import LQRController\n",
    "from double_pendulum.utils.plotting import plot_timeseries, plotEllipseSections\n",
    "from double_pendulum.utils.misc_roa import sampleFromEllipsoid, quadForm\n",
    "from double_pendulum.filter.lowpass import lowpass_filter\n",
    "#from double_pendulum.utils.plotting import direct_sphere, sample_from_ellipsoid\n",
    "from double_pendulum.model.plant import DoublePendulumPlant\n",
    "from double_pendulum.controller.lqr.roa.roa_paropt import roa_lqr_opt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['animation.writer'] = \"pillow\"\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67fc1d1-b31c-4465-955d-7b170436aff9",
   "metadata": {},
   "source": [
    "The next cell introduces the model of the robot. You can change the between acrobot and pendubot by commenting/uncommenting the second and third lines. In this cell we also generate the plant and simulator. These allow us to run simulations as well as experiments on the real system. Update the first line of the next cell with the motors on the pendulum assigned to you in order to be able to run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15ced4-dfce-4169-b50d-425a11913c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "motors = [403, 379] # REPLACE WITH YOUR MOTOR IDS [SHOULDER, ELBOW]\n",
    "model = \"model_07\"\n",
    "#robot = \"acrobot\"\n",
    "robot = \"pendubot\"\n",
    "\n",
    "if robot == \"pendubot\":\n",
    "    torque_limit = [0.15, 0.0]\n",
    "    active_act = 0\n",
    "elif robot == \"acrobot\":\n",
    "    torque_limit = [0.0, 0.15]\n",
    "    active_act = 1\n",
    "friction_compensation=False\n",
    "model_par_path = \"identified_parameters/\" + model + \"/model_parameters.yml\"\n",
    "mpar = model_parameters(filepath=model_par_path)\n",
    "mpar_con = model_parameters(filepath=model_par_path)\n",
    "mpar_con.set_motor_inertia(0.0)\n",
    "mpar_con.set_damping([0.0, 0.0])\n",
    "mpar_con.set_cfric([0.0, 0.0])\n",
    "if friction_compensation:\n",
    "    mpar_con.set_damping([0.004,0.004])\n",
    "    mpar_con.set_cfric([0.00305,0.0007777])\n",
    "mpar_con.set_torque_limit(torque_limit)\n",
    "# mpar.set_length([0.05,0.10])\n",
    "print(mpar_con)\n",
    "\n",
    "dt = 0.002\n",
    "tf = 10\n",
    "integrator = \"runge_kutta\"\n",
    "\n",
    "plant = SymbolicDoublePendulum(model_pars=mpar_con)\n",
    "sim = Simulator(plant=plant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8be2a9-291f-4205-a343-e8d5fc24ac01",
   "metadata": {},
   "source": [
    "## 1. Derivation\n",
    "\n",
    "The following section is based on Chapter 8 of Russ Tedrake's Underactuated Robotics.\n",
    "\n",
    "The Linear-Quadratic Regulator (LQR) is the simplest example of an optimal controller. It provides a controller that, subjet to a linear-quadratic cost function, optimizes the evolution of a linear system. This means that need to formulate the dynamics of the system so that they conform to the following shape:\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}} = f(\\mathbf{x}, \\mathbf{u}) = A \\mathbf{x} + B \\mathbf{u}\n",
    "$$\n",
    "\n",
    "We can then define the linear-quadratic cost function:\n",
    "\n",
    "$$\n",
    "J = \\int_{t_0}^{t_f} \\left(\\mathbf{x}^T Q \\mathbf{x} + \\mathbf{u}^T R \\mathbf{u} \\right)dt\n",
    "$$\n",
    "\n",
    "where Q and R are symmetric positive-definite matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785795ce-f9f5-4391-8824-dd9d560acd95",
   "metadata": {},
   "source": [
    "### The Hamilton-Jacobi-Bellman equation\n",
    "\n",
    "To solve the infinite-horizon optimal control problem, we use the Hamilton-Jacobi-Bellman equation.\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{u}} \\left( \\ell(\\mathbf{x}, \\mathbf{u}) + \\frac{\\partial J^*}{\\partial \\mathbf{x}} f(\\mathbf{x}, \\mathbf{u}) \\right) = 0\n",
    "$$\n",
    "\n",
    "where $\\ell$ is the cost function. and $f$ is the system dynamics (in the shape $\\dot{\\mathbf{x}} = f(\\mathbf{x}, \\mathbf{u})$). $J^*$ is the optimal cost-to-go, that is, the cost that will be accumulated by running the system from this point following an optimal policy. The idea behind it is to find a policy which will minimize the cost function as time trends toward infinity.\n",
    "\n",
    "We can then formulate the Hamilton-Jacobi-Bellman equation for this cost function:\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{u}} \\left( \\mathbf{x}^T Q \\mathbf{x} + \\mathbf{u}^T R \\mathbf{u} + \\frac{\\partial J^*}{\\partial \\mathbf{x}} \\left( A \\mathbf{x} + B \\mathbf{u} \\right) \\right) = 0, \\; \\; \\forall \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ca299-2725-4e35-b67b-dbe226649d52",
   "metadata": {},
   "source": [
    "The optimal cost-to-go function is quadratic, which means we can write it in the following shape:\n",
    "\n",
    "$$\n",
    "J^* (\\mathbf{x})= \\mathbf{x}^T S \\mathbf{x}\n",
    "$$\n",
    "\n",
    "Then we can rewrite the gradient of the cost-to-go function as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J^*}{\\partial \\mathbf{x}} = 2 \\mathbf{x}^T S\n",
    "$$\n",
    "\n",
    "Now the derivative of the cost HJB equation with respect to $\\mathbf{u}$ is equalized it to 0 to find the minimum:\n",
    "\n",
    "$$\n",
    "2 \\mathbf{u}^T R + 2 \\mathbf{x}^TSB = 0\n",
    "$$\n",
    "\n",
    "From the last equation, we isolate the optimal control law:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}^* = \\pi^*(\\mathbf{x}) = - R^{-1} B^T S \\mathbf{x} = -\\mathbf{K} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "Since we know this is an optimal policy, it satisfies the HJB equation. We insert it back and simplify:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^T \\left( Q - SBR^{-1}B^TS + 2SA\\right) \\mathbf{x} = 0\n",
    "$$\n",
    "\n",
    "Which can then be rearranged:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^T \\left( Q - SBR^{-1}B^TS + SA + A^TS \\right)\\mathbf{x} = 0\n",
    "$$\n",
    "\n",
    "Since the previous equality holds for all $\\mathbf{x}$, the term in parenthesis must be a null matrix:\n",
    "\n",
    "$$\n",
    "A^TS + SA - SBR^{-1}B^TS + Q = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "This is a version of the Algebraic Riccati Equation. After solving it, we get $S$ and then we can derive the optimal control law for setpoint control:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}^* = -R^{-1}B^TS \\mathbf{x} = -\\mathbf{K} \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f76280-cd89-4e50-9684-965a7b1571fc",
   "metadata": {},
   "source": [
    "### Linearization\n",
    "\n",
    "The previous procedure of deriving the optimal gain for our controller assumes that the system is linear. To apply this approach to nonlinear systems, we must first linearize it. From the dynamics $\\dot{\\mathbf{x}} = A\\mathbf{x} + B\\mathbf{u}$, we may linearize the dynamics of our system about a point using the a first order Taylor series:\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}} \\approx A_{lin} \\mathbf{x} + B_{lin} {\\mathbf{u}}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "A_{lin} = \\frac{\\partial A}{\\partial \\mathbf{x}} \\bigg|_{\\mathbf{x} = \\mathbf{x_{SP}}} \\; \\; \\; \\; \\; \\; B_{lin} = \\frac{\\partial B}{\\partial \\mathbf{x}} \\bigg|_{\\mathbf{x} = \\mathbf{x_{SP}}}\n",
    "$$\n",
    "\n",
    "The setpoint which we will be operating around is $\\mathbf{x_{SP}} = \\left[ \\begin{array}{cccc} \\pi & 0 & 0 & 0 \\end{array} \\right]$. The system dynamics will be decently approximated in the neighborhood of the setpoint. The further away from the setpoint, the less accurate the approximation becomes.\n",
    "\n",
    "This linearization is defined in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87572fb5-dc8a-4b0e-a2cb-a95c11e7fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_linear_matrices(self):\n",
    "    \"\"\"\n",
    "    symbolic A- and B-matrix of the linearized dynamics (xd = Ax+Bu)\n",
    "    \"\"\"\n",
    "    Alin = diff_to_matrix(smp.diff(self.f, self.x))\n",
    "    Alin = sub_symbols(Alin, self.x, self.x0)\n",
    "    Alin = sub_symbols(Alin, self.u, self.u0)\n",
    "\n",
    "    Blin = diff_to_matrix(smp.diff(self.f, self.u)).T\n",
    "    Blin = sub_symbols(Blin, self.x, self.x0)\n",
    "    Blin = sub_symbols(Blin, self.u, self.u0)\n",
    "\n",
    "    return Alin, Blin.T\n",
    "\n",
    "SymbolicDoublePendulum.symbolic_linear_matrices = symbolic_linear_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d757f-74cd-4d60-9e89-58cae32f5dd3",
   "metadata": {},
   "source": [
    "## 2. Implementation\n",
    "\n",
    "We now create our LQR controller. In the next cell, the cost matrices $Q$ and $R$ are defined. We also add a low-pass filter to clean the the readings of the encoders. This cell also prints out the controller gain $\\mathbf{K}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a974c-5bc8-43ca-b0ce-a9fd8c9baab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [3.09216976, 0.26000977, -0.0349345, 0.02595628]\n",
    "\n",
    "if robot == \"acrobot\":\n",
    "\n",
    "    Q = np.diag([0.0, 0.0, 0.0, 0.0])\n",
    "    R = np.diag([0.0, 0.0])\n",
    "\n",
    "elif robot == \"pendubot\":\n",
    "\n",
    "    Q = np.diag([0.0, 0.0, 0.0, 0.0])\n",
    "    R = np.diag([0.0, 0.0])\n",
    "    \n",
    "goal = [np.pi, 0, 0, 0]\n",
    "controller = LQRController(model_pars=mpar_con)\n",
    "controller.set_goal(goal)\n",
    "controller.set_cost_matrices(Q=Q, R=R)\n",
    "controller.set_parameters(failure_value=0, cost_to_go_cut=10000)\n",
    "\n",
    "if friction_compensation:\n",
    "    controller.set_friction_compensation(damping=[0.004,0.004], coulomb_fric=[0.00305,0.0007777])\n",
    "\n",
    "# Filter args\n",
    "lowpass_alpha=[1.0,1.0,0.9,0.9]\n",
    "filter_velocity_cut=0.1\n",
    "#controller_real.set_filter(filter1) # Uncomment to add filter to the controller\n",
    "\n",
    "controller.init()\n",
    "print(\"Controller gain K:\", getattr(controller, \"K\", \"Not set\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd344dd-b776-4a75-8ab7-399126c6fa94",
   "metadata": {},
   "source": [
    "### Think-Pair-Share\n",
    "\n",
    "Run the next cell to simulate the controller from an initial state close to the setpoint. If the LQR is unable to hold the position, try adjusing $Q$ and $R$ matrices, running the previous cell again and then run the simulation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86545023-e452-4201-8062-740af3eab881",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, X, U, anim = sim.simulate_and_animate(\n",
    "    t0=0.0,\n",
    "    x0=x0,\n",
    "    tf=tf,\n",
    "    dt=dt,\n",
    "    controller=controller,\n",
    "    integrator=integrator,\n",
    "    save_video=False,\n",
    "    anim_dt=dt\n",
    ")\n",
    "html = HTML(anim.to_jshtml())\n",
    "display(html)\n",
    "plt.close()\n",
    "\n",
    "plot_timeseries(\n",
    "    T,\n",
    "    X,\n",
    "    U,\n",
    "    pos_y_lines=[0, np.pi],\n",
    "    tau_y_lines=[-torque_limit[active_act], torque_limit[active_act]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de918ac-65d2-43e7-a98c-ff1df2f5bc51",
   "metadata": {},
   "source": [
    "Now we will try the controller on the real system. The first thing we will do is create a new controller with a low-pass filter. This will allow us to smooth out high-frequency changes in the state of the robot, avoiding overreaction to quick fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a3f89-9079-43cb-87a1-2f0b9da2d6d5",
   "metadata": {},
   "source": [
    "For the experiment, run the next cell, balance the pendulum on its upright position and then press enter (in that order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a6b5a-a839-4b6c-942d-7c72a657cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LQR test\n",
    "a=robot\n",
    "print(a)\n",
    "T, X, U, U_des = sim.run_experiment(\n",
    "    tf=tf,\n",
    "    dt=dt,\n",
    "    controller=controller,\n",
    "    experiment_type=\"DoublePendulum\",\n",
    "    motors = motors # [shoulder, elbow]\n",
    "    # actuated_joint=\"Both\"\n",
    ")\n",
    "plot_timeseries(\n",
    "    T,\n",
    "    X,\n",
    "    U,\n",
    "    T_des=T,\n",
    "    U_des=U_des,\n",
    "    pos_y_lines=[0, np.pi],\n",
    "    tau_y_lines=[-torque_limit[active_act], torque_limit[active_act]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52c614-3428-43d8-b371-89e1767cd8ba",
   "metadata": {},
   "source": [
    "It is very likely that the first experiment failed. Often, the simulation and the real system have slight differences that make it necessary to tune the $Q$ and $R$ matrices for each separately. If the experiment failed, try modifying the cost matrices and running the experiment again until the controller can stabilize the system.\n",
    "When the pendulum is able to stay upright, try to disturb it and see if it returns to the goal position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce084530-aa80-4ed2-bea3-de922b5e4c92",
   "metadata": {},
   "source": [
    "## 3. Region of Attraction\n",
    "\n",
    "As we saw, this controller is generally only able to stabilize the double pendulum if the initial state is close to the setpoint. We can approximate a set of initial states that will result in the system being stabilized. This set receives the name **Region of Attraction (RoA)**\n",
    "\n",
    "LaSalle's invariance principle states that if, for a system with continuous dynamics defined by $\\dot{x} = f(x)$, we can produce a scalar function $V(x)$ with continuous derivatives for which we have:\n",
    "\n",
    "- $V(\\mathbf{x})>0 \\;\\;\\; \\forall \\mathbf{x} \\in \\mathcal{G}, \\mathbf{x} \\neq \\mathbf{0}$ and $V(\\mathbf{0}) = 0$\n",
    "- $\\dot{V}(\\mathbf{x}) \\leq 0 \\;\\;\\; \\forall \\mathbf{x} \\in \\mathcal{G}$\n",
    "\n",
    "then, the origin is locally asymptotically stable and set $\\mathcal{G}$ is contained within its region of attraction.\n",
    "\n",
    "We can exploit this information to narrow down a set which is entirely within the region of attraction of the origin $x = \\left[ \\begin{matrix} \\pi & 0 & 0 & 0\\end{matrix} \\right]^T$. A simple way of doing so is to pick a shape for set $\\mathcal{G}$ and scale it so that it is within the region of attraction. \n",
    "\n",
    "We will use an ellipsoid centered on the origin and defined by:\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}) \\leq \\rho\n",
    "$$\n",
    "\n",
    "For our $V(\\mathbf{x})$ function we will use the optimal cost-to-go. Explicitly, this means that $V(\\mathbf{x}) = \\mathbf{x}^T S \\mathbf{x}$.\n",
    "\n",
    "To find the value of $\\rho$ that provides the largest region of attraction guaranteeing stability, we can follow the procedure:\n",
    "\n",
    "- Set an initial value of $\\rho$ which we know is unrealistically large.\n",
    "- Start sampling points from inside the ellipsoid. If at that point the conditions outlined in LaSalle's invariance principle hold, that point is part of the region of attraction. If LaSalle's principle of invariance does not hold for that point, we reduce the size of the ellipsoid until the point is no longer in it.\n",
    "- We repeat the previous step until we converge to the largest ellipsoid which only contains points in the region of attraction.\n",
    "\n",
    "The next cell defines a function which produces an ellipsoid around the origin with ceritified stability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398d04f-28bb-48a3-a0df-aa84bc75081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_roa_najafi(plant, controller, goal, S, n):\n",
    "    rho = 10.0\n",
    "    for i in range(n):\n",
    "        # sample initial state from sublevel set\n",
    "        # check if it fullfills Lyapunov conditions\n",
    "        x_bar = sampleFromEllipsoid(S, rho)\n",
    "        x = goal + x_bar\n",
    "        \n",
    "        tau = controller.get_control_output(x)\n",
    "\n",
    "        xdot = plant.rhs(0, x, tau)\n",
    "\n",
    "        V = quadForm(S, x_bar)\n",
    "\n",
    "        Vdot = 2 * np.dot(x_bar, np.dot(S, xdot))\n",
    "\n",
    "        if V < rho and Vdot > 0.0:\n",
    "            # if one of the lyapunov conditions is not satisfied\n",
    "            rho = V\n",
    "\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d241f-647d-4484-92de-db709e9719ad",
   "metadata": {},
   "source": [
    "Run the next cell to identify the size of the region of attraction of the controller and plot sections of the RoA around the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b4249-0e99-444d-bbdd-69e26929fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = estimate_roa_najafi(plant = plant,\n",
    "                            controller = controller,\n",
    "                            goal = np.array([np.pi, 0, 0, 0]),\n",
    "                            S = np.asarray(controller.S),\n",
    "                            n = 10000)\n",
    "print(\"rho: \", rho)\n",
    "plotEllipseSections([np.pi, 0, 0, 0], rho, np.asarray(controller.S))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12812b9-60ca-42d6-ac27-cf445bfe79cc",
   "metadata": {},
   "source": [
    "### Think-Pair-Share\n",
    "\n",
    "Do the sections of the region of attraction reflect the real behaviour of the controller?\n",
    "If the RoA seems exceedingly small, it means that the system is not stable around the origin. How can we use the estimation of the RoA to improve the stability of our system?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0d58c-2351-4dd0-8390-d1f60dca2643",
   "metadata": {},
   "source": [
    "## 4. Maximizing the RoA with CMA-ES\n",
    "\n",
    "As you have been able to see, tuning $Q$ and $R$ for this system can be very tricky. However, one set of tools that can be exploited to improve the stability of the system are optimization algorithms like **CMA-ES** (Covariance matrix adaptation evolution strategies). This optimization algorithm does not require derivatives, which makes it ideal for problems in which the relation between the cost matrices and the output of the controller are hard to present using differentiable expressions. The way CMA-ES works for our problem is by trying different combinations of weights for the $Q$ and $R$ cost matrices. The objective function tries to maximize $\\rho$. \n",
    "\n",
    "CMA-ES operates by sampling candidate solutions and evaluating them to update a covariance matrix that guides the following sampling steps.\n",
    "\n",
    "### Think-Pair-Share\n",
    "\n",
    "Run the following cell with different initial guesses (*init_pars*). Be sure to increase *maxfevals* for more refined results. You may also increase the number of cores you are using for this optimization to speed it up. By default, the optimization uses the model parameters defined at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01bc83e-c844-4577-b4dd-ef266862fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"roa_opt\"\n",
    "c_par = roa_lqr_opt(\n",
    "    model_par=mpar_con,\n",
    "    goal=goal,\n",
    "    init_pars=[1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "    par_prefactors=[20.0, 20.0, 10.0, 10.0, 10.0],\n",
    "    bounds=[[0, 1], [0, 1], [0, 1], [0, 1], [0, 1]],\n",
    "    maxfevals=100, #needs to be higher for proper optimization e.g. =1000\n",
    "    sigma0=0.4,\n",
    "    roa_backend=\"najafi\",\n",
    "    najafi_evals=50,\n",
    "    robot=robot,\n",
    "    save_dir=\"data/\"+filename,\n",
    "    plots=True,\n",
    "    num_proc=5, # more cores are needed for reasonable runtime, be sure to leave a few for yourself.\n",
    "    popsize_factor=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc91c96-fab5-4eb3-9744-62b6f174b4e0",
   "metadata": {},
   "source": [
    "Run the following cell to plot the sections of the resulting Region of Attraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e964b6-3672-4ca4-9632-e9914bb9c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_new = np.loadtxt('data/'+filename+'/rho')\n",
    "S_new = np.loadtxt('data/'+filename+'/Smatrix')\n",
    "\n",
    "plotEllipseSections(goal, rho_new, S_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc442d-d002-4881-a546-98893c1fdec5",
   "metadata": {},
   "source": [
    "Use CMA-ES to maximize the RoA of your controller and substitute the results of the optimization into its $Q$ and $R$ matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23464b9-5e59-47bd-9e8f-cb54c912c93c",
   "metadata": {},
   "source": [
    "### Think-Pair-Share\n",
    "\n",
    "Until now, we have been working with pendubot, which is arguably the easier version of this problem. Try to optimize the RoA of a controller for **acrobot**. You may allow a bit of torque from the unpowered motor if you dont succeed in stabilizing the real robot in acrobot mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bbb10d-415f-4f68-b5fa-df7773a4f717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
